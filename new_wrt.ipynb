{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e3bc175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: tensorboard in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.4.0) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.4.0) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.4.0) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.4.0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.4.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.4.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.4.0) (2024.12.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorboard) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorboard) (3.10)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorboard) (2.3.5)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorboard) (25.0)\n",
      "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorboard) (11.3.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorboard) (5.29.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorboard) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.4.0) (1.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers>=4.51.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers>=4.51.3) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers>=4.51.3) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers>=4.51.3) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers>=4.51.3) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers>=4.51.3) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers>=4.51.3) (2025.9.18)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers>=4.51.3) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers>=4.51.3) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers>=4.51.3) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers>=4.51.3) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers>=4.51.3) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers>=4.51.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers>=4.51.3) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers>=4.51.3) (2025.8.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets==3.3.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (3.3.2)\n",
      "Requirement already satisfied: accelerate==1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.4.0)\n",
      "Requirement already satisfied: evaluate==0.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.4.3)\n",
      "Requirement already satisfied: trl==0.21.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.21.0)\n",
      "Requirement already satisfied: peft==0.14.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.14.0)\n",
      "Requirement already satisfied: protobuf<6.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (5.29.5)\n",
      "Requirement already satisfied: fsspec==2024.12.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2024.12.0)\n",
      "Requirement already satisfied: gcsfs==2024.12.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2024.12.0)\n",
      "Requirement already satisfied: sentencepiece in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.2.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets==3.3.2) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets==3.3.2) (2.3.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets==3.3.2) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets==3.3.2) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets==3.3.2) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets==3.3.2) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets==3.3.2) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets==3.3.2) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets==3.3.2) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets==3.3.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets==3.3.2) (0.35.3)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets==3.3.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets==3.3.2) (6.0.3)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from accelerate==1.4.0) (7.1.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from accelerate==1.4.0) (2.9.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from accelerate==1.4.0) (0.6.2)\n",
      "Requirement already satisfied: transformers>=4.55.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from trl==0.21.0) (4.57.1)\n",
      "Requirement already satisfied: decorator>4.1.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gcsfs==2024.12.0) (5.2.1)\n",
      "Requirement already satisfied: google-auth>=1.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gcsfs==2024.12.0) (2.41.1)\n",
      "Requirement already satisfied: google-auth-oauthlib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gcsfs==2024.12.0) (1.2.3)\n",
      "Requirement already satisfied: google-cloud-storage in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gcsfs==2024.12.0) (3.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp->datasets==3.3.2) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp->datasets==3.3.2) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp->datasets==3.3.2) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp->datasets==3.3.2) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp->datasets==3.3.2) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp->datasets==3.3.2) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp->datasets==3.3.2) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets==3.3.2) (3.10)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-auth>=1.2->gcsfs==2024.12.0) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-auth>=1.2->gcsfs==2024.12.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-auth>=1.2->gcsfs==2024.12.0) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth>=1.2->gcsfs==2024.12.0) (0.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets==3.3.2) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets==3.3.2) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.2->datasets==3.3.2) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.2->datasets==3.3.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.2->datasets==3.3.2) (2025.8.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate==1.4.0) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate==1.4.0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate==1.4.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate==1.4.0) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.4.0) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers>=4.55.0->trl==0.21.0) (2025.9.18)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers>=4.55.0->trl==0.21.0) (0.22.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-auth-oauthlib->gcsfs==2024.12.0) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs==2024.12.0) (3.3.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.27.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-storage->gcsfs==2024.12.0) (2.28.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-storage->gcsfs==2024.12.0) (2.5.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-storage->gcsfs==2024.12.0) (2.8.0)\n",
      "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-storage->gcsfs==2024.12.0) (1.7.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage->gcsfs==2024.12.0) (1.72.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage->gcsfs==2024.12.0) (1.26.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->accelerate==1.4.0) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets==3.3.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets==3.3.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets==3.3.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.3.2) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install Pytorch & other libraries\n",
    "# standard torch is sufficient for Mac\n",
    "%pip install \"torch>=2.4.0\" tensorboard\n",
    "\n",
    "# Install Gemma release branch\n",
    "%pip install \"transformers>=4.51.3\"\n",
    "\n",
    "# Install Hugging Face libraries\n",
    "%pip install --upgrade \\\n",
    "  \"datasets==3.3.2\" \\\n",
    "  \"accelerate==1.4.0\" \\\n",
    "  \"evaluate==0.4.3\" \\\n",
    "  \"trl==0.21.0\" \\\n",
    "  \"peft==0.14.0\" \\\n",
    "  \"protobuf>=3.20.3,<6.0.0dev\" \\\n",
    "  \"fsspec==2024.12.0\" \\\n",
    "  \"gcsfs==2024.12.0\" \\\n",
    "  sentencepiece\n",
    "\n",
    "# Removed flash-attn and bitsandbytes (not strictly needed for MPS LoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330b552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = \"\"\"\n",
    "###EXAMPLE 1:\n",
    "\n",
    "### Candidate details / Job target:\n",
    "Position: 13 years of exp || Solidity, C#, JavaScript || CTO / VP / Tech Lead Full stack\n",
    "More info: Who am I:\n",
    "- 13 years of commercial experience as a software engineer (web projects, customers from Europe and US);\n",
    "- 5 years in roles of team lead, tech lead, architect (including coding);\n",
    "- constant learner (books, courses, youtube);\n",
    "- C1 (Advanced) level of English (IELTS General = 7/9);\n",
    "- tech languages: C#, JavaScript, Solidity;\n",
    "- ready to learn Rust/Go.\n",
    "\n",
    "What can I bring in:\n",
    "- develop your web/blockchain project from gathering requirements stage to deployment and maintenance;\n",
    "- build a team of highly qualified and responsible professionals;\n",
    "- build processes or improve existing ones;\n",
    "- design architectures, code features, perform code reviews and so on.\n",
    "\n",
    "What can I technically (in short):\n",
    "- С#: 12 years of exp; .Net Core, .Net 6, MS SQL, EF, Clean Architecture, anything related to web platforms;\n",
    "- JavaScript: 7 years of exp; Node.js, React.js, Angular;\n",
    "- Solidity: since March 2021; upgradeable, secure, metamorphic, ERC20, ERC721, ERC1155, EIP1967, diamonds, proxies, clones, beacons, play-to-earn, vulnerabilities, on-chain/off-chain data storage, oracles, push/pull, tests, deployment, Truffle, Hardhat, Ganache, Mocha, Chai, web3.js, ether.js, OpenZeppelin, IPFS;\n",
    "- Databases: MS SQL (and any relational), NoSQL (MongoDB);\n",
    "- CI/CD: GitLab, TeamCity, BitBucket, Azure CI/CD Pipelines, GitHub Actions.\n",
    "Looking For: I am interested in:\n",
    "- part-time engagement;\n",
    "- blockchain projects (DeFi, NFT, Gaming, Metaverse);\n",
    "- high salary (I apply to jobs paid $120+ per hour);\n",
    "- roles of a researcher and/or a leader rather than just coder;\n",
    "- ability to work remotely from Bali (with that said, I'm ok with visiting office during initial months to earn your respect and trust);\n",
    "- freedom in taking decisions;\n",
    "- time zone of Europe or Asia;\n",
    "- 1-2 interviews as a max, with tech specialists and managers.\n",
    "\n",
    "I am not interested in:\n",
    "- US time zone (I'd prefer morning shifts starting at 7am rather than coding till midnight);\n",
    "- strict \"fabric\" schedule like \"9-to-6\", \"10-to-7\", \"11-to-8\" and so on (since in IT this is an indicator of the unprofessional nature of the team and management);\n",
    "- jobs with a requirement of overall experience in software development of just a few years (I have 12, and the job offered should be my next challenge);\n",
    "- calls with HRs for \"just to have a 30 minutes blah-blah-blah\" (I have a prepared list of questions, and I hope you have prepared too);\n",
    "- if I have no word from you at any of the stages for more than a week - I am not more interested in the job;\n",
    "- I may consider test tasks only for tech lead or CTO roles, and it should be prepaid (for free you may have a look at my github and linkedin).\n",
    "Highlights: Landed a role of Director of Blockchain Development in a metaverse project in Feb, 2022\n",
    "Primary Keyword: Lead\n",
    "\n",
    "### Additional instructions:\n",
    "Tone: professional, one-page.\n",
    "\n",
    "### RESUME1:\n",
    "\n",
    "[Your Name]\n",
    "CTO / VP of Engineering / Lead Blockchain Architect Location: Bali, Indonesia (Remote) | [LinkedIn Profile URL] | [GitHub Profile URL] | [Email Address]\n",
    "\n",
    "PROFESSIONAL SUMMARY\n",
    "\n",
    "Senior Technology Leader with 13+ years of commercial engineering experience and 5+ years in architectural and leadership roles. Expert in Solidity and Blockchain ecosystems (DeFi, GameFi, Metaverse) coupled with a deep foundation in C#/.NET and JavaScript. Proven track record of building high-performance distributed teams, designing secure decentralized architectures, and driving projects from requirements gathering to deployment. Strategic thinker capable of bridging the gap between complex technical implementation and high-level business goals.\n",
    "\n",
    "TECHNICAL ARSENAL\n",
    "\n",
    "Blockchain & Web3: Solidity (Expert), Smart Contracts (ERC20, ERC721, ERC1155), Upgradable Proxies (EIP1967, Diamonds), Security/Vulnerabilities, OpenZeppelin, Truffle, Hardhat, Web3.js, Ethers.js, IPFS, Oracles (Chainlink).\n",
    "\n",
    "Back-End & Architecture: C# (12 years), .NET Core/.NET 6, Node.js, Clean Architecture, Microservices, REST APIs, Design Patterns.\n",
    "\n",
    "Front-End: JavaScript (7 years), React.js, Angular, Web Platforms.\n",
    "\n",
    "Data & DevOps: MS SQL, MongoDB, Azure CI/CD, GitHub Actions, TeamCity, Docker.\n",
    "\n",
    "Leadership: Agile/Scrum, Team Building, Code Reviews, Strategic Planning, Process Optimization.\n",
    "\n",
    "PROFESSIONAL EXPERIENCE\n",
    "\n",
    "Director of Blockchain Development / Lead Architect | [Company Name - Metaverse Project] February 2022 – Present Leveraged deep expertise in GameFi and Metaverse architecture to lead technical strategy.\n",
    "\n",
    "Strategic Leadership: Directed the full lifecycle of blockchain development, translating business vision into technical roadmaps and secure architecture.\n",
    "\n",
    "Smart Contract Architecture: Designed and deployed complex contract systems including Upgradeable contracts (Proxies, Diamonds), NFT marketplaces, and Play-to-Earn mechanics.\n",
    "\n",
    "Team Building: Built and mentored a team of highly qualified developers, establishing code quality standards, automated testing protocols (Mocha/Chai), and security best practices.\n",
    "\n",
    "Process Improvement: Implemented CI/CD pipelines (GitHub Actions/Azure) to streamline deployment to testnets and mainnets, reducing release friction.\n",
    "\n",
    "Tech Lead / Senior Full Stack Engineer | [Company Name] 2017 – 2022 Transitioned from Senior Developer to Tech Lead, overseeing web platforms and distributed systems.\n",
    "\n",
    "Architecture & Design: Led the migration and development of enterprise-scale web applications using .NET Core and React.js, focusing on Clean Architecture principles.\n",
    "\n",
    "Technical Management: Conducted code reviews, managed sprint planning, and acted as the primary technical point of contact for stakeholders in the US and Europe.\n",
    "\n",
    "Performance Optimization: Optimized SQL and NoSQL database queries and server-side logic, resulting in significant improvements in application latency and throughput.\n",
    "\n",
    "Senior Software Engineer (.NET/C#) | [Company Name] 2012 – 2017\n",
    "\n",
    "Delivered robust web solutions for international clients using the full Microsoft technology stack.\n",
    "\n",
    "Specialized in backend logic, database design (MS SQL), and API integrations.\n",
    "\n",
    "Consistently maintained high code coverage and adhered to strict delivery timelines in an Agile environment.\n",
    "\n",
    "NOTABLE PROJECTS & ACHIEVEMENTS\n",
    "\n",
    "Metaverse/GameFi: Architected on-chain/off-chain data synchronization strategies and economy balancing for high-traffic gaming assets.\n",
    "\n",
    "DeFi Protocols: Developed secure staking mechanisms and tokenomics structures utilizing standard ERC implementations and custom logic.\n",
    "\n",
    "Security Focus: Successfully audited and patched vulnerabilities in smart contracts prior to mainnet launches, ensuring zero fund loss.\n",
    "\n",
    "EDUCATION & LANGUAGES\n",
    "\n",
    "Bachelor of Science in Computer Science (or relevant degree) | [University Name]\n",
    "\n",
    "English: Advanced (C1) – IELTS General 7.0\n",
    "\n",
    "\n",
    "\n",
    "###EXAMPLE 2:\n",
    "\n",
    "### Candidate details / Job target:\n",
    "Position: 1С Developer\n",
    "More info: 1C 8.2, 8.3 programming, reports, processing, SKD.\n",
    "UPP, custom configurations, managed and usual forms,\n",
    "JSON, XML, XDTO, FTP, WEB services, WS-link, HTTP, REST API, Jira\n",
    "COM – connection, COM-port, RLS, extension, mobile application, Administration 1C, configuration store\n",
    "writing an external component in C#\n",
    "Basic knowledge: HTML5, CSS3, JavaScript, Node.js, React, MongoDB, SQL\n",
    "Looking For: \n",
    "Highlights: \n",
    "Primary Keyword: Other\n",
    "\n",
    "### Additional instructions:\n",
    "Tone: professional, one-page.\n",
    "\n",
    "###RESUME 2:\n",
    "[Your Name]\n",
    "[City, State, Zip Code] | [Phone Number] | [Email Address] [LinkedIn Profile URL] | [GitHub/Portfolio URL (Optional)]\n",
    "\n",
    "Professional Summary\n",
    "\n",
    "Highly skilled 1C Developer with extensive experience in 1C:Enterprise 8.2 and 8.3 platforms. Proven track record in developing and maintaining complex configurations (including UPP), designing custom reports using SKD, and implementing RLS. Expert in system integration, utilizing REST/HTTP services, COM connections, and writing external components in C#. Combines deep backend 1C logic with broad knowledge of web technologies (HTML/JS/React) to deliver robust, full-cycle business automation solutions.\n",
    "\n",
    "Technical Skills\n",
    "\n",
    "1C Core & Development: 1C:Enterprise 8.2/8.3, Managed & Ordinary Forms, SKD (Data Composition System), RLS (Row Level Security), Extensions, Configuration Store, Administration, Mobile Applications.\n",
    "\n",
    "Configurations: UPP (Manufacturing Enterprise Management), Custom Configurations.\n",
    "\n",
    "Integration & Data Exchange: HTTP, REST API, Web Services (SOAP), WS-Link, JSON, XML, XDTO, FTP, COM-connection, COM-port handling.\n",
    "\n",
    "Advanced Extensions: Writing external components in C#.\n",
    "\n",
    "Database & Tools: SQL, Jira.\n",
    "\n",
    "Web Stack (Basic Proficiency): HTML5, CSS3, JavaScript, Node.js, React, MongoDB.\n",
    "\n",
    "Professional Experience\n",
    "\n",
    "Senior 1C Developer | [Company Name] | [Location] [Month, Year] – Present\n",
    "\n",
    "Architect and develop custom modifications for UPP and proprietary configurations on the 1C 8.3 platform, utilizing both managed and ordinary forms.\n",
    "\n",
    "Design high-performance data exchange mechanisms between 1C and external systems using REST API, HTTP services, JSON, and XML/XDTO.\n",
    "\n",
    "Develop external components in C# to solve non-standard hardware integration tasks and extend native platform functionality.\n",
    "\n",
    "Implement complex reporting systems using SKD and optimize existing queries for improved database performance.\n",
    "\n",
    "Configure and maintain RLS (Row Level Security) to ensure strict data access control across various user roles.\n",
    "\n",
    "Manage the full development lifecycle within Jira, ensuring timely delivery of extensions and updates.\n",
    "\n",
    "1C Developer | [Company Name] | [Location] [Month, Year] – [Month, Year]\n",
    "\n",
    "Supported and updated 1C:Enterprise 8.2/8.3 configurations, ensuring stability and data integrity.\n",
    "\n",
    "Developed mobile applications on the 1C platform for warehouse and remote field operations.\n",
    "\n",
    "Established automated data transfers via FTP and Web Services, ensuring seamless synchronization with third-party software.\n",
    "\n",
    "Handled COM-port device connections and COM-connection integration for hardware peripherals.\n",
    "\n",
    "Performed 1C Administration duties, including database maintenance, user management, and configuration store versioning.\n",
    "\n",
    "Education\n",
    "\n",
    "[Degree Name, e.g., Bachelor of Science in Computer Science] [University Name], [City, State]\n",
    "\n",
    "Certifications & Languages\n",
    "\n",
    "Certifications: [E.g., 1C:Professional, 1C:Specialist]\n",
    "\n",
    "Languages: [List languages, e.g., English (Intermediate), Russian (Native)]\n",
    "\n",
    "###EXAMPLE 3:\n",
    "### Candidate details / Job target:\n",
    "Position: 2D Animator, 2D Artist\n",
    "More info: - 2D artist and animator for games.\n",
    "- Experience 3+ years \n",
    "\n",
    "- Excellent knowledge of Moho, Spine and After Effects for animation\n",
    "- Excellent knowledge of Photoshop, Illustrator for 2d raster and vector art\n",
    "- ZBrush, 3dsMax, Maya basic knowledge\n",
    "- Bachelor of Fine Arts\n",
    "- 4 years working as a Designer (creating brands identity, advertising)\n",
    "Looking For: - I am aspired to create great games\n",
    "- I enjoy creating characters, backgrounds, UI, and animation\n",
    "- Flexible schedule is preferable for me\n",
    "Highlights: Here is my portfolio:\n",
    "https://readymag.com/u66498178/portfolio\n",
    "\n",
    "I`ve worked as a slots artist for games in casino style, animated characters for fighting platformer game and created a bunch of movies!\n",
    "Primary Keyword: Other\n",
    "\n",
    "### Additional instructions:\n",
    "Tone: professional, one-page.\n",
    "###RESUME 3:\n",
    "[Your Name]\n",
    "[City, State, Country] | [Phone Number] | [Email Address] Portfolio: https://readymag.com/u66498178/portfolio\n",
    "\n",
    "Professional Summary\n",
    "\n",
    "Creative and versatile 2D Animator & Artist with 3+ years of experience in game development and a strong foundation in graphic design (4 years). Expert in the full visual pipeline, ranging from character design, backgrounds, and UI to complex rigging and animation using Spine, Moho, and After Effects. Passionate about creating immersive gaming experiences with a proven track record in both casino-style games and action platformers.\n",
    "\n",
    "Technical Skills\n",
    "\n",
    "2D Animation: Spine 2D, Moho (Anime Studio), Adobe After Effects, Rigging, Character Animation, VFX.\n",
    "\n",
    "2D Art & Design: Adobe Photoshop, Adobe Illustrator, Character Design, Background Art, UI/UX Elements, Vector & Raster Art.\n",
    "\n",
    "3D Foundation: Basic proficiency in ZBrush, 3ds Max, Autodesk Maya.\n",
    "\n",
    "Core Competencies: Game Art Pipelines, Visual Storytelling, Brand Identity, Anatomy & Motion.\n",
    "\n",
    "Professional Experience\n",
    "\n",
    "2D Animator & Game Artist | [Company Name / Freelance] | [Location/Remote] [Month, Year] – Present\n",
    "\n",
    "Game Animation: Orchestrated fluid character animations for a fighting platformer game, utilizing Spine and Moho to create responsive combat mechanics and idle cycles.\n",
    "\n",
    "Casino/Slots Art: Designed and animated high-quality assets for casino-style slot games, ensuring engaging visual feedback and user retention.\n",
    "\n",
    "Full-Stack Art Production: Created production-ready assets across multiple categories, including Character Art, Background Environments, and User Interface (UI) elements.\n",
    "\n",
    "Cinematics: Produced animated short movies and cutscenes for game narratives and promotional materials using After Effects.\n",
    "\n",
    "Collaborated closely with developers to ensure art assets were optimized for game engines while maintaining visual fidelity.\n",
    "\n",
    "Graphic Designer | [Company Name] | [Location] [Month, Year] – [Month, Year]\n",
    "\n",
    "Spent 4 years specializing in Brand Identity and Advertising, developing a keen eye for composition, color theory, and typography.\n",
    "\n",
    "Managed visual projects from concept to final delivery, ensuring consistency across various media formats.\n",
    "\n",
    "Mastered vector illustration in Adobe Illustrator and photo manipulation in Photoshop, creating the technical foundation for a transition into game art.\n",
    "\n",
    "Education\n",
    "\n",
    "Bachelor of Fine Arts (BFA) [University/College Name], [City, State]\n",
    "\n",
    "Projects & Highlights\n",
    "\n",
    "Fighting Platformer: Responsible for the complete animation cycle of main characters, including attack combos and damage states.\n",
    "\n",
    "Slot Machine Games: Designed cohesive themes (symbols, backgrounds, and UI) for multiple slot titles.\n",
    "\n",
    "Portfolio: https://readymag.com/u66498178/portfolio\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d767ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "complex_cot = (\n",
    "    \"- Identify key skills from the candidate's past roles.\\n\"\n",
    "    \"- Match these skills to the job description keywords.\\n\"\n",
    "    \"- Prioritize experiences that show measurable achievements.\"\n",
    ")\n",
    "\n",
    "system_instruction = f\"\"\"Below is an instruction that describes a task, paired with an input that provides candidate details and a target job.\n",
    "Write a professional, ATS-friendly resume tailored to the target role.\n",
    "### Strategy:\n",
    "{complex_cot}\n",
    "\n",
    "First, produce a concise 2–4 bullet **Plan**. Then generate the resume.\n",
    "Use clear section headers. For experience bullets, use the STAR/impact style.\n",
    "\n",
    "Output format:\n",
    "Plan:\n",
    "- <short bullet 1>\n",
    "- <short bullet 2>\n",
    "\n",
    "Resume:\n",
    "[Use sections: Summary, Experience, Education, Skills, Projects/Certifications]\n",
    "\n",
    "### Exapmles:\n",
    "{examples}\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"### Candidate details / Job target:\n",
    "{}\n",
    "\n",
    "### Additional instructions:\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457b7f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d142736e090c4849ade89996442f6b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5c88abb6e148ada71a9cd890c80b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d029433c72493690a4b69de6a73df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60646612a1394fe7ac4cd0481b44425a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9d197968fe4037a727a439965aa559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/857 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52d05f2899644628630f78fb82323db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/39.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bc017bcef34b3eb0b441642fc59a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f524f558afa406697812718dd290891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98998368ecd744ffab94fa34f4e76fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4b03e35e684780ad48e985e49381b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d936caaa67a64f43bb739b9a975ceb75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      6\u001b[39m bnb_config = BitsAndBytesConfig(\n\u001b[32m      7\u001b[39m     load_in_4bit=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      8\u001b[39m     bnb_4bit_quant_type=\u001b[33m\"\u001b[39m\u001b[33mnf4\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     bnb_4bit_compute_dtype=torch.float16,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMODEL_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 3. DEFINE GENERATION FUNCTION\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_resume\u001b[39m(candidate_details):\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# Construct the User Input part\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/modeling_utils.py:5029\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   5027\u001b[39m \u001b[38;5;66;03m# Prepare the full device map\u001b[39;00m\n\u001b[32m   5028\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5029\u001b[39m     device_map = \u001b[43m_get_device_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5031\u001b[39m \u001b[38;5;66;03m# Finalize model weight initialization\u001b[39;00m\n\u001b[32m   5032\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m from_tf:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/modeling_utils.py:1365\u001b[39m, in \u001b[36m_get_device_map\u001b[39m\u001b[34m(model, device_map, max_memory, hf_quantizer, dtype, keep_in_fp32_regex)\u001b[39m\n\u001b[32m   1362\u001b[39m     device_map = infer_auto_device_map(model, dtype=target_dtype, **device_map_kwargs)\n\u001b[32m   1364\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m         \u001b[43mhf_quantizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1367\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1368\u001b[39m     tied_params = find_tied_parameters(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:127\u001b[39m, in \u001b[36mBnb4BitHfQuantizer.validate_environment\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head.values() \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head.values():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    128\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSome modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    129\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mquantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    130\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33min 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    131\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`from_pretrained`. Check \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    132\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfor more details. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "MODEL_ID = \"google/gemma-2-9b-it\" \n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. DEFINE GENERATION FUNCTION\n",
    "# ---------------------------------------------------------\n",
    "def generate_resume(candidate_details):\n",
    "    # Construct the User Input part\n",
    "    user_input_formatted = f\"\"\"### Candidate details / Job target:\n",
    "{candidate_details}\n",
    "\n",
    "### Additional instructions:\n",
    "Tone: professional, one-page.\"\"\"\n",
    "\n",
    "    # Gemma typically puts \"System\" instructions inside the User prompt \n",
    "    # or uses a specific chat template structure. \n",
    "    # We will combine your system instruction + user input.\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": system_instruction + \"\\n\\n\" + user_input_formatted}\n",
    "    ]\n",
    "\n",
    "    # Apply Chat Template (Crucial for correct special tokens)\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        return_tensors=\"pt\", \n",
    "        add_generation_prompt=True\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=2000,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. RUN\n",
    "# ---------------------------------------------------------\n",
    "test_candidate = \"\"\"Position: Senior Python Developer\n",
    "More info: 6 years exp in Django/FastAPI. Built a logistics engine reducing costs by 15%.\n",
    "Looking For: Remote, FinTech, $90k+.\"\"\"\n",
    "\n",
    "print(generate_resume(test_candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "519ecd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.3.16.tar.gz (50.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from llama-cpp-python) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from llama-cpp-python) (2.3.5)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from llama-cpp-python) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.16-cp313-cp313-macosx_15_0_arm64.whl size=3801087 sha256=0b21cd01e03278f85ae5dc9f06fa1209b15d1022661882c0d9137c5fcc8f465d\n",
      "  Stored in directory: /Users/ihorivanyshyn/Library/Caches/pip/wheels/af/3a/b6/445d9f4ccadd3ed923d55af8f055f2ccd217c66f09c834f0d8\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: diskcache, llama-cpp-python\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [llama-cpp-python]\n",
      "\u001b[1A\u001b[2KSuccessfully installed diskcache-5.6.3 llama-cpp-python-0.3.16\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# This installs with Metal support for Mac\n",
    "!CMAKE_ARGS=\"-DLLAMA_METAL=on\" pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10a934a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (8192) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "llama_kv_cache_unified_iswa: using full-size SWA cache (ref: https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's the plan and the resume based on the provided candidate details and the implied target role of Machine Learning Engineer.\n",
      "\n",
      "**Plan:**\n",
      "\n",
      "*   Highlight Python, scikit-learn, and PyTorch as core technical skills.\n",
      "*   Emphasize mathematical foundation and its relevance to ML.\n",
      "*   Showcase contribution to the CV writing project to demonstrate practical application.\n",
      "*   Mention UCU CS education to establish a solid academic background.\n",
      "\n",
      "**Resume:**\n",
      "\n",
      "[Your Name]\n",
      "[Your City, State] | [Your Phone Number] | [Your Email Address] | [Your LinkedIn Profile URL (Optional)] | [Your GitHub Profile URL (Optional)]\n",
      "\n",
      "**Summary**\n",
      "\n",
      "Results-oriented Machine Learning Engineer with one year of experience developing and implementing machine learning solutions using Python, scikit-learn, and PyTorch.  Possessing a strong mathematical foundation and demonstrated ability to apply machine learning techniques to solve real-world problems.  Eager to contribute to innovative projects and further develop expertise in the field.\n",
      "\n",
      "**Experience**\n",
      "\n",
      "**Machine Learning Engineer** | [Company Name - If Applicable, Otherwise Remove] | [City, State] | [Month, Year] – [Present]\n",
      "\n",
      "*   Developed and evaluated machine learning models using Python, scikit-learn, and PyTorch for [briefly mention project type if available, otherwise omit].\n",
      "*   Leveraged a strong mathematical background to optimize model performance and interpret results effectively.\n",
      "*   Contributed to a CV writing project, applying machine learning techniques to [specify tasks performed, e.g., automated skill extraction, resume scoring].\n",
      "*   [Add another bullet if you have more specific accomplishments from the role. Example: Implemented data preprocessing pipelines for improved model accuracy.]\n",
      "\n",
      "**Education**\n",
      "\n",
      "**Bachelor of Computer Science** | Ukrainian Catholic University (UCU) | Lviv, Ukraine | [Year of Graduation]\n",
      "\n",
      "*   Focused on [mention relevant coursework, e.g., algorithms, data structures, linear algebra, probability and statistics].\n",
      "*   [Optional: Mention relevant projects or thesis topic if impactful]\n",
      "\n",
      "**Skills**\n",
      "\n",
      "*   **Programming Languages:** Python\n",
      "*   **Machine Learning Libraries:** scikit-learn, PyTorch, Pandas, NumPy\n",
      "*   **Mathematics:** Linear Algebra, Calculus, Probability & Statistics\n",
      "*   **Data Manipulation:** Data Cleaning, Feature Engineering\n",
      "*   **Tools:** Git, [Any other relevant tools you used]\n",
      "\n",
      "**Projects**\n",
      "\n",
      "*   **CV Writing Project:** Developed and implemented [briefly describe the machine learning techniques used and the results achieved in the CV writing project]. [Link to GitHub repo if available]\n",
      "\n",
      "\n",
      "\n",
      "**Important Considerations:**\n",
      "\n",
      "*   **Replace placeholders:** Fill in the bracketed information with your specific details.\n",
      "*   **Quantify achievements:** Whenever possible, try to quantify your achievements with numbers (e.g., \"Improved model accuracy by X%\").\n",
      "*   **Tailor to the job description:**  Carefully review the job description for the specific role you're applying for and adjust the resume accordingly.  Highlight the skills and experiences that are most relevant to the position.\n",
      "*   **GitHub/Portfolio:**  If you have a GitHub profile or online portfolio showcasing your projects, include the link.\n",
      "*   **Formatting:** Ensure the resume is well-formatted, easy to read, and ATS-friendly (avoiding tables or complex layouts).  Use clear section headings and consistent formatting throughout.\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Update this path to where you downloaded the .gguf file\n",
    "model_path = \"./gemma-3-12b-it-Q4_K_M.gguf\"\n",
    "\n",
    "# n_gpu_layers=-1 means \"put everything on the GPU/Neural Engine\"\n",
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_gpu_layers=-1, \n",
    "    n_ctx=8192,  # Gemma supports large context\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "system_instruction = system_instruction\n",
    "candidate_details = \"One year ml engeneer, python, sklearn, torch, good in math, contributed to cv writing project, education UCU CS\"\n",
    "\n",
    "prompt = f\"\"\"<start_of_turn>user\n",
    "{system_instruction}\n",
    "\n",
    "### Candidate details:\n",
    "{candidate_details}<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "\n",
    "output = llm(\n",
    "    prompt,\n",
    "    max_tokens=1000,\n",
    "    stop=[\"<end_of_turn>\"],\n",
    "    echo=False\n",
    ")\n",
    "\n",
    "print(output['choices'][0]['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
