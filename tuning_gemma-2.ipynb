{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "68f01232abaa47718f7ef9e2b385ea90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d67b0c30c5dc428bb94b5376742452de",
              "IPY_MODEL_2e136c54e57e423aad12e09b72f3f2db",
              "IPY_MODEL_06156ce41f6f4cef826df04fe7c7668a"
            ],
            "layout": "IPY_MODEL_c0e092d8246e4fcfb76d32fde246f011"
          }
        },
        "d67b0c30c5dc428bb94b5376742452de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_806b9c46e3bc48eea7ce641b71313e35",
            "placeholder": "​",
            "style": "IPY_MODEL_b1dad699601c4b58ba5d2b17d499fa5c",
            "value": "Map: 100%"
          }
        },
        "2e136c54e57e423aad12e09b72f3f2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64223308b485428ebb341b9100b28865",
            "max": 210250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bedd061d72dc4a8981e234db482c563e",
            "value": 210250
          }
        },
        "06156ce41f6f4cef826df04fe7c7668a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_211f7721061846a6becdd722c2d80db9",
            "placeholder": "​",
            "style": "IPY_MODEL_2791c7881e124ad9bd14d3bc0fd3fc08",
            "value": " 210250/210250 [00:13&lt;00:00, 18132.80 examples/s]"
          }
        },
        "c0e092d8246e4fcfb76d32fde246f011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "806b9c46e3bc48eea7ce641b71313e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1dad699601c4b58ba5d2b17d499fa5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64223308b485428ebb341b9100b28865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bedd061d72dc4a8981e234db482c563e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "211f7721061846a6becdd722c2d80db9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2791c7881e124ad9bd14d3bc0fd3fc08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c98683c74cb34538839e8ed442dbaa33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10e68bcf1f32449fb8d4211038f1d337",
              "IPY_MODEL_0faa59509c3840b9bccfcd92b5f46473",
              "IPY_MODEL_f503860364c647bca0e595491d438dba"
            ],
            "layout": "IPY_MODEL_5aa22693de6444589279638a1032ca0a"
          }
        },
        "10e68bcf1f32449fb8d4211038f1d337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6e82784af8c43bf8540d02ad0cad973",
            "placeholder": "​",
            "style": "IPY_MODEL_04c6d2c613c44dca913b8e0f745acc54",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0faa59509c3840b9bccfcd92b5f46473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81b12796230e4eaa90c9c92e7cd0b76e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_498a2566825e4d4da69bcc44fa3cecb3",
            "value": 2
          }
        },
        "f503860364c647bca0e595491d438dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f488b48615843a9921dd7d7173c6d14",
            "placeholder": "​",
            "style": "IPY_MODEL_91c85ef0061c4ec6832f83c7a868e4a8",
            "value": " 2/2 [00:53&lt;00:00, 25.95s/it]"
          }
        },
        "5aa22693de6444589279638a1032ca0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6e82784af8c43bf8540d02ad0cad973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04c6d2c613c44dca913b8e0f745acc54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81b12796230e4eaa90c9c92e7cd0b76e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "498a2566825e4d4da69bcc44fa3cecb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f488b48615843a9921dd7d7173c6d14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c85ef0061c4ec6832f83c7a868e4a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHXUpnvcTdpq",
        "outputId": "7fbf42de-f700-4359-c12f-0bf19085c9f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0) (1.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Requirement already satisfied: transformers>=4.51.3 in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (2025.11.12)\n",
            "Requirement already satisfied: datasets==3.3.2 in /usr/local/lib/python3.12/dist-packages (3.3.2)\n",
            "Requirement already satisfied: accelerate==1.4.0 in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: evaluate==0.4.3 in /usr/local/lib/python3.12/dist-packages (0.4.3)\n",
            "Requirement already satisfied: bitsandbytes==0.45.3 in /usr/local/lib/python3.12/dist-packages (0.45.3)\n",
            "Requirement already satisfied: trl==0.21.0 in /usr/local/lib/python3.12/dist-packages (0.21.0)\n",
            "Requirement already satisfied: peft==0.14.0 in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: protobuf<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (5.29.5)\n",
            "Requirement already satisfied: fsspec==2024.12.0 in /usr/local/lib/python3.12/dist-packages (2024.12.0)\n",
            "Requirement already satisfied: gcsfs==2024.12.0 in /usr/local/lib/python3.12/dist-packages (2024.12.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (3.13.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (6.0.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (0.7.0)\n",
            "Requirement already satisfied: transformers>=4.55.0 in /usr/local/lib/python3.12/dist-packages (from trl==0.21.0) (4.57.3)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.12/dist-packages (from gcsfs==2024.12.0) (4.4.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.12/dist-packages (from gcsfs==2024.12.0) (2.43.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.12/dist-packages (from gcsfs==2024.12.0) (1.2.2)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (from gcsfs==2024.12.0) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (1.22.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs==2024.12.0) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs==2024.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs==2024.12.0) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.3.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.3.2) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.3.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.3.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.3.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.3.2) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.55.0->trl==0.21.0) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.55.0->trl==0.21.0) (0.22.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib->gcsfs==2024.12.0) (2.0.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.27.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs==2024.12.0) (2.28.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs==2024.12.0) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs==2024.12.0) (2.8.0)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs==2024.12.0) (1.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.3.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.3.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.3.2) (2025.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage->gcsfs==2024.12.0) (1.72.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage->gcsfs==2024.12.0) (1.26.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs==2024.12.0) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.3.2) (1.17.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs==2024.12.0) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.4.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.4.0) (3.0.3)\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from flash-attn) (2.9.0+cu126)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->flash-attn) (3.0.3)\n",
            "Building wheels for collected packages: flash-attn\n"
          ]
        }
      ],
      "source": [
        "# Install Pytorch & other libraries\n",
        "%pip install \"torch>=2.4.0\" tensorboard\n",
        "\n",
        "# Install Gemma release branch from Hugging Face\n",
        "%pip install \"transformers>=4.51.3\"\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "# FIX: Pinned fsspec and gcsfs to 2024.12.0 to satisfy datasets==3.3.2 requirements\n",
        "%pip install  --upgrade \\\n",
        "  \"datasets==3.3.2\" \\\n",
        "  \"accelerate==1.4.0\" \\\n",
        "  \"evaluate==0.4.3\" \\\n",
        "  \"bitsandbytes==0.45.3\" \\\n",
        "  \"trl==0.21.0\" \\\n",
        "  \"peft==0.14.0\" \\\n",
        "  \"protobuf>=3.20.3,<6.0.0dev\" \\\n",
        "  \"fsspec==2024.12.0\" \\\n",
        "  \"gcsfs==2024.12.0\" \\\n",
        "  sentencepiece\n",
        "\n",
        "# COMMENT IN: if you are running on a GPU that supports BF16 data type and flash attn, such as NVIDIA L4 or NVIDIA A100\n",
        "%pip install flash-attn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from getpass import getpass\n",
        "from huggingface_hub import login\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
        "import torch\n",
        "import threading\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import evaluate\n",
        "\n",
        "print(\"Loading descriptions dataset...\")\n",
        "descriptions = pd.read_parquet(\"hf://datasets/lang-uk/recruitment-dataset-job-descriptions-english/data/train-00000-of-00001.parquet\")\n",
        "print(\"Descriptions head:\")\n",
        "print(descriptions.head())\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"Loading profiles dataset...\")\n",
        "profile = pd.read_parquet(\"hf://datasets/lang-uk/recruitment-dataset-candidate-profiles-english/data/train-00000-of-00001.parquet\")\n",
        "print(\"Profiles head:\")\n",
        "print(profile.head())\n",
        "print(\"-\" * 30)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "print(\"Logging in to Hugging Face Hub...\")\n",
        "\n",
        "print(\"Loading metrics...\")\n",
        "\n",
        "try:\n",
        "    HF_TOKEN = getpass()\n",
        "    login(HF_TOKEN)\n",
        "    print(\"Login successful.\")\n",
        "except Exception as e:\n",
        "    print(f\"Login failed: {e}\")\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO0bc5UvVaMk",
        "outputId": "e9377b1c-f23e-4f83-8f9c-3db5b472aec7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading descriptions dataset...\n",
            "Descriptions head:\n",
            "                                            Position  \\\n",
            "0      10 + Blockchain Nodes / Masternodes to set up   \n",
            "1       10 .NET Developers (Middle and Senior level)   \n",
            "2  10X Engineer (co-founder, #4 employee, USD 11-...   \n",
            "3                          16 - Amazon Brand Manager   \n",
            "4                          16 - Amazon Brand Manager   \n",
            "\n",
            "                                    Long Description    Company Name  \\\n",
            "0  *Requirements*\\r\\n\\r\\nWe're looking for a long...    MyCointainer   \n",
            "1  Greetings! My name is Maria, I am in urgent ne...  TechScout.tech   \n",
            "2  **Product**\\r\\nThe product is a live video cha...        Innoteka   \n",
            "3  Currently, TCM expanding its activities to Ukr...       FirstFive   \n",
            "4  Hello,\\r\\nWe, MIMIRB2B, are an outstaff compan...        MimirB2B   \n",
            "\n",
            "  Exp Years Primary Keyword English Level                  Published  \\\n",
            "0        2y        Sysadmin  intermediate  2020-10-01T00:00:00+03:00   \n",
            "1        2y            .NET  intermediate  2022-03-01T00:00:00+02:00   \n",
            "2        5y      JavaScript        fluent  2021-07-01T00:00:00+03:00   \n",
            "3        2y       Marketing         upper  2022-01-01T00:00:00+02:00   \n",
            "4        1y       Marketing         upper  2021-12-01T00:00:00+02:00   \n",
            "\n",
            "  Long Description_lang                                    id  \\\n",
            "0                    en  c0ca96e7-85df-50df-a64e-d934cd02a170   \n",
            "1                    en  64f4b7ea-36e4-5bdd-a8b1-185f32f7dc7f   \n",
            "2                    en  b9a1303e-dd0c-5ed1-8f62-be2bc4c7da4f   \n",
            "3                    en  99cb3f4a-9b4b-53d9-9a3b-bab2c22da346   \n",
            "4                    en  bc1419f7-28e2-582b-8d53-22e28b2f0210   \n",
            "\n",
            "   __index_level_0__  \n",
            "0              27461  \n",
            "1              27462  \n",
            "2              27463  \n",
            "3              27464  \n",
            "4              27465  \n",
            "------------------------------\n",
            "Loading profiles dataset...\n",
            "Profiles head:\n",
            "                                            Position  \\\n",
            "0  13 years of exp || Solidity, C#, JavaScript ||...   \n",
            "1                                       1c Developer   \n",
            "2                                       1C developer   \n",
            "3                                       1C Developer   \n",
            "4                     #1 Customer Support Specialist   \n",
            "\n",
            "                                            Moreinfo  \\\n",
            "0  Who am I:\\r\\n- 13 years of commercial experien...   \n",
            "1  Worked on a mobile application for tracking trips   \n",
            "2  1 am an 1C developer. I deployed an 1C to typo...   \n",
            "3  Perfect knowledge of  1C:Enterprise Platform.\\...   \n",
            "4  Tech addicted, experienced customer support wi...   \n",
            "\n",
            "                                         Looking For  \\\n",
            "0  I am interested in:\\r\\n- part-time engagement;...   \n",
            "1                                               None   \n",
            "2                                               None   \n",
            "3                                               None   \n",
            "4  In terms of the nature of the Customer Support...   \n",
            "\n",
            "                                          Highlights Primary Keyword  \\\n",
            "0  Landed a role of Director of Blockchain Develo...            Lead   \n",
            "1                                               None           Other   \n",
            "2                                               None         Flutter   \n",
            "3                                               None           Other   \n",
            "4  thousands of resolved problems, also, thousand...         Support   \n",
            "\n",
            "  English Level  Experience Years  \\\n",
            "0        fluent              11.0   \n",
            "1  intermediate               3.0   \n",
            "2  intermediate              11.0   \n",
            "3  intermediate              11.0   \n",
            "4        fluent               2.5   \n",
            "\n",
            "                                                  CV CV_lang  \\\n",
            "0  Landed a role of Director of Blockchain Develo...      en   \n",
            "1  \\nWorked on a mobile application for tracking ...      en   \n",
            "2  \\n1 am an 1C developer. I deployed an 1C to ty...      en   \n",
            "3  \\nPerfect knowledge of  1C:Enterprise Platform...      en   \n",
            "4  thousands of resolved problems, also, thousand...      en   \n",
            "\n",
            "                                     id  __index_level_0__  \n",
            "0  50534b61-6826-52b1-9ac5-bfd2cfa348ec              24230  \n",
            "1  c2b9ea56-b5c8-50ec-a63b-053a5c8ff467              24231  \n",
            "2  b3bfe3ed-ec25-56b2-8aaa-8c629120538e              24232  \n",
            "3  163fb9a3-3695-5dc3-b1d0-e0038ce4d0a5              24233  \n",
            "4  3f201183-db58-5333-9139-74c16059dc4a              24234  \n",
            "------------------------------\n",
            "Using device: cuda\n",
            "Logging in to Hugging Face Hub...\n",
            "Loading metrics...\n",
            "··········\n",
            "Login successful.\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "complex_cot = (\n",
        "    \"- Identify key skills from the candidate's past roles.\\n\"\n",
        "    \"- Match these skills to the job description keywords.\\n\"\n",
        "    \"- Prioritize experiences that show measurable achievements.\"\n",
        ")\n",
        "\n",
        "system_instruction = f\"\"\"Below is an instruction that describes a task, paired with an input that provides candidate details and a target job.\n",
        "Write a professional, ATS-friendly resume tailored to the target role.\n",
        "### Strategy:\n",
        "{complex_cot}\n",
        "\n",
        "First, produce a concise 2–4 bullet **Plan**. Then generate the resume.\n",
        "Use clear section headers. For experience bullets, use the STAR/impact style.\n",
        "\n",
        "Output format:\n",
        "Plan:\n",
        "- <short bullet 1>\n",
        "- <short bullet 2>\n",
        "\n",
        "Resume:\n",
        "[Use sections: Summary, Experience, Education, Skills, Projects/Certifications]\"\"\"\n",
        "\n",
        "user_prompt = \"\"\"### Candidate details / Job target:\n",
        "{}\n",
        "\n",
        "### Additional instructions:\n",
        "{}\"\"\"\n",
        "\n",
        "\n",
        "def format_prompts_and_refs(df, extra_instructions=\"Tone: professional, one-page.\"):\n",
        "    candidate_details = [\n",
        "        f\"Position: {p}\\nMore info: {m}\\nLooking For: {l}\\nHighlights: {h}\\nPrimary Keyword: {k}\"\n",
        "        for p, m, l, h, k in zip(\n",
        "            df[\"Position\"].fillna(''),\n",
        "            df[\"Moreinfo\"].fillna(''),\n",
        "            df[\"Looking For\"].fillna(''),\n",
        "            df[\"Highlights\"].fillna(''),\n",
        "            df[\"Primary Keyword\"].fillna('')\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    prompts = [\n",
        "        user_prompt.format(details, extra_instructions)\n",
        "        for details in candidate_details\n",
        "    ]\n",
        "\n",
        "    references = [\n",
        "        f\"{h}\\n{m}\"\n",
        "        for h, m in zip(df[\"Highlights\"].fillna(''), df[\"Moreinfo\"].fillna(''))\n",
        "    ]\n",
        "\n",
        "    return prompts, references\n",
        "\n",
        "formatted_prompts, formatted_refs = format_prompts_and_refs(profile)\n",
        "\n",
        "# Create dataset with messages - NO pre-tokenization to save memory\n",
        "# The tokenization will be done lazily by the trainer\n",
        "def create_messages_list():\n",
        "    messages_list = []\n",
        "    for prompt, resume in zip(formatted_prompts, profile[\"CV\"]):\n",
        "        messages_list.append({\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": system_instruction},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "                {\"role\": \"assistant\", \"content\": resume}\n",
        "            ]\n",
        "        })\n",
        "    return messages_list\n",
        "\n",
        "print(\"Creating dataset with lazy loading...\")\n",
        "messages_data = create_messages_list()\n",
        "dataset = Dataset.from_list(messages_data)\n",
        "\n",
        "print(f\"Dataset size: {len(dataset)} samples\")\n",
        "print(\"Sample user prompt:\")\n",
        "print(dataset[0][\"messages\"][1][\"content\"][:500], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817,
          "referenced_widgets": [
            "68f01232abaa47718f7ef9e2b385ea90",
            "d67b0c30c5dc428bb94b5376742452de",
            "2e136c54e57e423aad12e09b72f3f2db",
            "06156ce41f6f4cef826df04fe7c7668a",
            "c0e092d8246e4fcfb76d32fde246f011",
            "806b9c46e3bc48eea7ce641b71313e35",
            "b1dad699601c4b58ba5d2b17d499fa5c",
            "64223308b485428ebb341b9100b28865",
            "bedd061d72dc4a8981e234db482c563e",
            "211f7721061846a6becdd722c2d80db9",
            "2791c7881e124ad9bd14d3bc0fd3fc08"
          ]
        },
        "id": "kBZMttmAWHpV",
        "outputId": "7f2a5f3c-6779-4d56-d95d-6d988a0cbdd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/210250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68f01232abaa47718f7ef9e2b385ea90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Candidate details / Job target:\n",
            "Position: 13 years of exp || Solidity, C#, JavaScript || CTO / VP / Tech Lead Full stack\n",
            "More info: Who am I:\r\n",
            "- 13 years of commercial experience as a software engineer (web projects, customers from Europe and US);\r\n",
            "- 5 years in roles of team lead, tech lead, architect (including coding);\r\n",
            "- constant learner (books, courses, youtube);\r\n",
            "- C1 (Advanced) level of English (IELTS General = 7/9);\r\n",
            "- tech languages: C#, JavaScript, Solidity;\r\n",
            "- ready to learn Rust/Go.\r\n",
            "\r\n",
            "What can I bring in:\r\n",
            "- develop your web/blockchain project from gathering requirements stage to deployment and maintenance;\r\n",
            "- build a team of highly qualified and responsible professionals;\r\n",
            "- build processes or improve existing ones;\r\n",
            "- design architectures, code features, perform code reviews and so on.\r\n",
            "\r\n",
            "What can I technically (in short):\r\n",
            "- С#: 12 years of exp; .Net Core, .Net 6, MS SQL, EF, Clean Architecture, anything related to web platforms;\r\n",
            "- JavaScript: 7 years of exp; Node.js, React.js, Angular;\r\n",
            "- Solidity: since March 2021; upgradeable, secure, metamorphic, ERC20, ERC721, ERC1155, EIP1967, diamonds, proxies, clones, beacons, play-to-earn, vulnerabilities, on-chain/off-chain data storage, oracles, push/pull, tests, deployment, Truffle, Hardhat, Ganache, Mocha, Chai, web3.js, ether.js, OpenZeppelin, IPFS;\r\n",
            "- Databases: MS SQL (and any relational), NoSQL (MongoDB);\r\n",
            "- CI/CD: GitLab, TeamCity, BitBucket, Azure CI/CD Pipelines, GitHub Actions.\n",
            "Looking For: I am interested in:\r\n",
            "- part-time engagement;\r\n",
            "- blockchain projects (DeFi, NFT, Gaming, Metaverse);\r\n",
            "- high salary (I apply to jobs paid $120+ per hour);\r\n",
            "- roles of a researcher and/or a leader rather than just coder;\r\n",
            "- ability to work remotely from Bali (with that said, I'm ok with visiting office during initial months to earn your respect and trust);\r\n",
            "- freedom in taking decisions;\r\n",
            "- time zone of Europe or Asia;\r\n",
            "- 1-2 interviews as a max, with tech specialists and managers.\r\n",
            "\r\n",
            "I am not interested in:\r\n",
            "- US time zone (I'd prefer morning shifts starting at 7am rather than coding till midnight);\r\n",
            "- strict \"fabric\" schedule like \"9-to-6\", \"10-to-7\", \"11-to-8\" and so on (since in IT this is an indicator of the unprofessional nature of the team and management);\r\n",
            "- jobs with a requirement of overall experience in software development of just a few years (I have 12, and the job offered should be my next challenge);\r\n",
            "- calls with HRs for \"just to have a 30 minutes blah-blah-blah\" (I have a prepared list of questions, and I hope you have prepared too);\r\n",
            "- if I have no word from you at any of the stages for more than a week - I am not more interested in the job;\r\n",
            "- I may consider test tasks only for tech lead or CTO roles, and it should be prepaid (for free you may have a look at my github and linkedin).\n",
            "Highlights: Landed a role of Director of Blockchain Development in a metaverse project in Feb, 2022\n",
            "Primary Keyword: Lead\n",
            "\n",
            "### Additional instructions:\n",
            "Tone: professional, one-page.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-pKX8qzdgbw",
        "outputId": "c46934da-a570-461f-8441-f2963bac472f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'content': \"Below is an instruction that describes a task, paired with an input that provides candidate details and a target job. \\nWrite a professional, ATS-friendly resume tailored to the target role. \\n### Strategy:\\n- Identify key skills from the candidate's past roles.\\n- Match these skills to the job description keywords.\\n- Prioritize experiences that show measurable achievements.\\n\\nFirst, produce a concise 2–4 bullet **Plan**. Then generate the resume. \\nUse clear section headers. For experience bullets, use the STAR/impact style.\\n\\nOutput format:\\nPlan:\\n- <short bullet 1>\\n- <short bullet 2>\\n\\nResume:\\n[Use sections: Summary, Experience, Education, Skills, Projects/Certifications]\",\n",
              "   'role': 'system'},\n",
              "  {'content': '### Candidate details / Job target:\\nPosition: 13 years of exp || Solidity, C#, JavaScript || CTO / VP / Tech Lead Full stack\\nMore info: Who am I:\\r\\n- 13 years of commercial experience as a software engineer (web projects, customers from Europe and US);\\r\\n- 5 years in roles of team lead, tech lead, architect (including coding);\\r\\n- constant learner (books, courses, youtube);\\r\\n- C1 (Advanced) level of English (IELTS General = 7/9);\\r\\n- tech languages: C#, JavaScript, Solidity;\\r\\n- ready to learn Rust/Go.\\r\\n\\r\\nWhat can I bring in:\\r\\n- develop your web/blockchain project from gathering requirements stage to deployment and maintenance;\\r\\n- build a team of highly qualified and responsible professionals;\\r\\n- build processes or improve existing ones;\\r\\n- design architectures, code features, perform code reviews and so on.\\r\\n\\r\\nWhat can I technically (in short):\\r\\n- С#: 12 years of exp; .Net Core, .Net 6, MS SQL, EF, Clean Architecture, anything related to web platforms;\\r\\n- JavaScript: 7 years of exp; Node.js, React.js, Angular;\\r\\n- Solidity: since March 2021; upgradeable, secure, metamorphic, ERC20, ERC721, ERC1155, EIP1967, diamonds, proxies, clones, beacons, play-to-earn, vulnerabilities, on-chain/off-chain data storage, oracles, push/pull, tests, deployment, Truffle, Hardhat, Ganache, Mocha, Chai, web3.js, ether.js, OpenZeppelin, IPFS;\\r\\n- Databases: MS SQL (and any relational), NoSQL (MongoDB);\\r\\n- CI/CD: GitLab, TeamCity, BitBucket, Azure CI/CD Pipelines, GitHub Actions.\\nLooking For: I am interested in:\\r\\n- part-time engagement;\\r\\n- blockchain projects (DeFi, NFT, Gaming, Metaverse);\\r\\n- high salary (I apply to jobs paid $120+ per hour);\\r\\n- roles of a researcher and/or a leader rather than just coder;\\r\\n- ability to work remotely from Bali (with that said, I\\'m ok with visiting office during initial months to earn your respect and trust);\\r\\n- freedom in taking decisions;\\r\\n- time zone of Europe or Asia;\\r\\n- 1-2 interviews as a max, with tech specialists and managers.\\r\\n\\r\\nI am not interested in:\\r\\n- US time zone (I\\'d prefer morning shifts starting at 7am rather than coding till midnight);\\r\\n- strict \"fabric\" schedule like \"9-to-6\", \"10-to-7\", \"11-to-8\" and so on (since in IT this is an indicator of the unprofessional nature of the team and management);\\r\\n- jobs with a requirement of overall experience in software development of just a few years (I have 12, and the job offered should be my next challenge);\\r\\n- calls with HRs for \"just to have a 30 minutes blah-blah-blah\" (I have a prepared list of questions, and I hope you have prepared too);\\r\\n- if I have no word from you at any of the stages for more than a week - I am not more interested in the job;\\r\\n- I may consider test tasks only for tech lead or CTO roles, and it should be prepaid (for free you may have a look at my github and linkedin).\\nHighlights: Landed a role of Director of Blockchain Development in a metaverse project in Feb, 2022\\nPrimary Keyword: Lead\\n\\n### Additional instructions:\\nTone: professional, one-page.',\n",
              "   'role': 'user'},\n",
              "  {'content': 'Landed a role of Director of Blockchain Development in a metaverse project in Feb, 2022\\nWho am I:\\r\\n- 13 years of commercial experience as a software engineer (web projects, customers from Europe and US);\\r\\n- 5 years in roles of team lead, tech lead, architect (including coding);\\r\\n- constant learner (books, courses, youtube);\\r\\n- C1 (Advanced) level of English (IELTS General = 7/9);\\r\\n- tech languages: C#, JavaScript, Solidity;\\r\\n- ready to learn Rust/Go.\\r\\n\\r\\nWhat can I bring in:\\r\\n- develop your web/blockchain project from gathering requirements stage to deployment and maintenance;\\r\\n- build a team of highly qualified and responsible professionals;\\r\\n- build processes or improve existing ones;\\r\\n- design architectures, code features, perform code reviews and so on.\\r\\n\\r\\nWhat can I technically (in short):\\r\\n- С#: 12 years of exp; .Net Core, .Net 6, MS SQL, EF, Clean Architecture, anything related to web platforms;\\r\\n- JavaScript: 7 years of exp; Node.js, React.js, Angular;\\r\\n- Solidity: since March 2021; upgradeable, secure, metamorphic, ERC20, ERC721, ERC1155, EIP1967, diamonds, proxies, clones, beacons, play-to-earn, vulnerabilities, on-chain/off-chain data storage, oracles, push/pull, tests, deployment, Truffle, Hardhat, Ganache, Mocha, Chai, web3.js, ether.js, OpenZeppelin, IPFS;\\r\\n- Databases: MS SQL (and any relational), NoSQL (MongoDB);\\r\\n- CI/CD: GitLab, TeamCity, BitBucket, Azure CI/CD Pipelines, GitHub Actions.\\nI am interested in:\\r\\n- part-time engagement;\\r\\n- blockchain projects (DeFi, NFT, Gaming, Metaverse);\\r\\n- high salary (I apply to jobs paid $120+ per hour);\\r\\n- roles of a researcher and/or a leader rather than just coder;\\r\\n- ability to work remotely from Bali (with that said, I\\'m ok with visiting office during initial months to earn your respect and trust);\\r\\n- freedom in taking decisions;\\r\\n- time zone of Europe or Asia;\\r\\n- 1-2 interviews as a max, with tech specialists and managers.\\r\\n\\r\\nI am not interested in:\\r\\n- US time zone (I\\'d prefer morning shifts starting at 7am rather than coding till midnight);\\r\\n- strict \"fabric\" schedule like \"9-to-6\", \"10-to-7\", \"11-to-8\" and so on (since in IT this is an indicator of the unprofessional nature of the team and management);\\r\\n- jobs with a requirement of overall experience in software development of just a few years (I have 12, and the job offered should be my next challenge);\\r\\n- calls with HRs for \"just to have a 30 minutes blah-blah-blah\" (I have a prepared list of questions, and I hope you have prepared too);\\r\\n- if I have no word from you at any of the stages for more than a week - I am not more interested in the job;\\r\\n- I may consider test tasks only for tech lead or CTO roles, and it should be prepaid (for free you may have a look at my github and linkedin).',\n",
              "   'role': 'assistant'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForImageTextToText, BitsAndBytesConfig\n",
        "\n",
        "model_id = \"google/gemma-3-4b-pt\" # or `google/gemma-3-4b-pt`, `google/gemma-3-12b-pt`, `google/gemma-3-27b-pt`\n",
        "\n",
        "if model_id == \"google/gemma-3-4b-pt\":\n",
        "    model_class = AutoModelForCausalLM\n",
        "else:\n",
        "    model_class = AutoModelForImageTextToText\n",
        "\n",
        "if torch.cuda.get_device_capability()[0] >= 8:\n",
        "    torch_dtype = torch.bfloat16\n",
        "else:\n",
        "    torch_dtype = torch.float16\n",
        "\n",
        "model_kwargs = dict(\n",
        "    attn_implementation=\"flash_attention_2\", # Use \"flash_attention_2\" when running on Ampere or newer GPU\n",
        "    torch_dtype=torch_dtype, # What torch dtype to use, defaults to auto\n",
        "    device_map=\"auto\", # Let torch decide how to load the model\n",
        ")\n",
        "\n",
        "model_kwargs[\"quantization_config\"] = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_compute_dtype=model_kwargs['torch_dtype'],\n",
        "    bnb_4bit_quant_storage=model_kwargs['torch_dtype'],\n",
        ")\n",
        "\n",
        "model = model_class.from_pretrained(model_id, **model_kwargs)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-4b-it\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c98683c74cb34538839e8ed442dbaa33",
            "10e68bcf1f32449fb8d4211038f1d337",
            "0faa59509c3840b9bccfcd92b5f46473",
            "f503860364c647bca0e595491d438dba",
            "5aa22693de6444589279638a1032ca0a",
            "f6e82784af8c43bf8540d02ad0cad973",
            "04c6d2c613c44dca913b8e0f745acc54",
            "81b12796230e4eaa90c9c92e7cd0b76e",
            "498a2566825e4d4da69bcc44fa3cecb3",
            "5f488b48615843a9921dd7d7173c6d14",
            "91c85ef0061c4ec6832f83c7a868e4a8"
          ]
        },
        "id": "yBxquADcdxxY",
        "outputId": "25ec2951-2716-488d-9dcb-9d7f72c88637"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c98683c74cb34538839e8ed442dbaa33"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    r=16,\n",
        "    bias=\"none\",\n",
        "    target_modules=\"all-linear\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    #modules_to_save=[\"lm_head\", \"embed_tokens\"] # make sure to save the lm_head and embed_tokens as you train the special tokens\n",
        ")"
      ],
      "metadata": {
        "id": "ub2V02NEibho"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTConfig\n",
        "\n",
        "args = SFTConfig(\n",
        "    output_dir=\"gemma-text-to-sql\",         # directory to save and repository id\n",
        "    max_seq_length=1024,                    # Reduced from 2048 - saves significant memory\n",
        "    packing=True,                           # Groups multiple samples in the dataset into a single sequence\n",
        "    num_train_epochs=3,                     # number of training epochs\n",
        "    per_device_train_batch_size=1,          # batch size per device during training\n",
        "    gradient_accumulation_steps=4,          # number of steps before performing a backward/update pass\n",
        "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": False},  # More memory efficient\n",
        "    optim=\"paged_adamw_8bit\",              # use paged adamw optimizer for 8-bit\n",
        "    logging_steps=10,                       # log every 10 steps\n",
        "    save_strategy=\"epoch\",                  # save checkpoint every epoch\n",
        "    learning_rate=2e-4,                     # learning rate, based on QLoRA paper\n",
        "    fp16=True if torch_dtype == torch.float16 else False,   # use float16 precision\n",
        "    bf16=True if torch_dtype == torch.bfloat16 else False,   # use bfloat16 precision\n",
        "    max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n",
        "    warmup_ratio=0.03,                      # warmup ratio based on QLoRA paper\n",
        "    lr_scheduler_type=\"constant\",           # use constant learning rate scheduler\n",
        "    push_to_hub=True,                       # push model to hub\n",
        "    report_to=\"tensorboard\",                # report metrics to tensorboard\n",
        "    dataset_text_field=\"\",                  # Will use messages field\n",
        "    dataset_num_proc=4,                     # Parallel processing for dataset\n",
        ")"
      ],
      "metadata": {
        "id": "rAZGa4IBihZc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    processing_class=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "a4PESlu1ikQQ",
        "outputId": "79878147-e549-4a36-bd5e-57844fcb36db"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.45 GiB is free. Process 5906 has 13.29 GiB memory in use. Of the allocated memory 12.64 GiB is allocated by PyTorch, and 524.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1240348560.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtrl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFTTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m trainer = SFTTrainer(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics, peft_config, formatting_func)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpeft_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_peft_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_peft_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# Data collator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36m_prepare_peft_model\u001b[0;34m(self, model, peft_config, args)\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0;31m# Prepare model for kbit training if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_qlora\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sharded_qlora\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_model_for_kbit_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m             \u001b[0;31m# Disable gradient checkpointing as it's handled by prepare_model_for_kbit_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_checkpointing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36m_prepare_model_for_kbit_training\u001b[0;34m(self, model, args)\u001b[0m\n\u001b[1;32m    638\u001b[0m         }\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mprepare_model_for_kbit_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mprepare_model_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_enable_gradient_checkpointing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSFTConfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/utils/other.py\u001b[0m in \u001b[0;36mprepare_model_for_kbit_training\u001b[0;34m(model, use_gradient_checkpointing, gradient_checkpointing_kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             ) and param.__class__.__name__ != \"Params4bit\":\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     if (\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.45 GiB is free. Process 5906 has 13.29 GiB memory in use. Of the allocated memory 12.64 GiB is allocated by PyTorch, and 524.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training, the model will be automatically saved to the Hub and the output directory\n",
        "trainer.train()\n",
        "\n",
        "# Save the final model again to the Hugging Face Hub\n",
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "V4yTCvuXlDXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# free the memory again\n",
        "del model\n",
        "del trainer\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "qZddSBPulELX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"gemma-text-to-sql\"\n",
        "\n",
        "# Load Model with PEFT adapter\n",
        "model = model_class.from_pretrained(\n",
        "  model_id,\n",
        "  device_map=\"auto\",\n",
        "  torch_dtype=torch_dtype,\n",
        "  attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "CCqDEQqLlF9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "from transformers import pipeline\n",
        "\n",
        "# 1. Setup the pipeline using your loaded model and tokenizer\n",
        "# Note: We use the model/tokenizer you loaded in previous steps\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# 2. Pick a random sample\n",
        "# We check if 'dataset' is a dictionary (has splits) or a list\n",
        "if hasattr(dataset, \"keys\") and \"test\" in dataset.keys():\n",
        "    data_source = dataset[\"test\"]\n",
        "else:\n",
        "    data_source = dataset # Fallback to using the training set if no test split exists\n",
        "\n",
        "rand_idx = randint(0, len(data_source) - 1)\n",
        "sample = data_source[rand_idx]\n",
        "\n",
        "# 3. Prepare the Prompt (System + User message only)\n",
        "messages = sample[\"messages\"][:2] # We exclude the assistant's answer (index 2)\n",
        "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "# 4. Generate the Resume\n",
        "# Increased max_new_tokens to 1024 because resumes are long\n",
        "terminators = [\n",
        "    tokenizer.eos_token_id,\n",
        "    tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")\n",
        "]\n",
        "\n",
        "outputs = pipe(\n",
        "    prompt,\n",
        "    max_new_tokens=1024,\n",
        "    do_sample=True,      # Set to True for more creative writing\n",
        "    temperature=0.7,     # 0.7 is better for creative writing (0.1 is for code/math)\n",
        "    top_k=50,\n",
        "    top_p=0.9,\n",
        "    eos_token_id=terminators,\n",
        ")\n",
        "\n",
        "# 5. Display Results\n",
        "generated_text = outputs[0]['generated_text'][len(prompt):].strip()\n",
        "user_input = messages[1]['content']\n",
        "target_resume = sample[\"messages\"][2]['content']\n",
        "\n",
        "print(f\"--- INPUT PROFILE ---\\n{user_input}\\n\")\n",
        "print(f\"--- TARGET RESUME (Ground Truth) ---\\n{target_resume[:500]}...\\n[Truncated]\\n\")\n",
        "print(f\"--- GENERATED RESUME ---\\n{generated_text}\")"
      ],
      "metadata": {
        "id": "54-UaNbGll3I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}